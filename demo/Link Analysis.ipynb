{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link Analysis is frequently used to visualize the relationships between nodes in a graph. In this case, we study the hyperlinks between domains that contain a certain term on the Web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking com.lucidworks.spark:spark-solr:3.6.0 for download\n",
      "-> Failed to resolve org.restlet.jee:org.restlet.ext.servlet:2.3.0\n",
      "    -> not found: /tmp/toree-tmp-dir2042813687803005472/toree_add_deps/cache/org.restlet.jee/org.restlet.ext.servlet/ivy-2.3.0.xml\n",
      "    -> download error: Caught java.io.IOException: Server returned HTTP response code: 403 for URL: https://repo1.maven.org/maven2/org/restlet/jee/org.restlet.ext.servlet/2.3.0/org.restlet.ext.servlet-2.3.0.pom (Server returned HTTP response code: 403 for URL: https://repo1.maven.org/maven2/org/restlet/jee/org.restlet.ext.servlet/2.3.0/org.restlet.ext.servlet-2.3.0.pom) while downloading https://repo1.maven.org/maven2/org/restlet/jee/org.restlet.ext.servlet/2.3.0/org.restlet.ext.servlet-2.3.0.pom\n",
      "-> Failed to resolve org.restlet.jee:org.restlet:2.3.0\n",
      "    -> not found: /tmp/toree-tmp-dir2042813687803005472/toree_add_deps/cache/org.restlet.jee/org.restlet/ivy-2.3.0.xml\n",
      "    -> download error: Caught java.io.IOException: Server returned HTTP response code: 403 for URL: https://repo1.maven.org/maven2/org/restlet/jee/org.restlet/2.3.0/org.restlet-2.3.0.pom (Server returned HTTP response code: 403 for URL: https://repo1.maven.org/maven2/org/restlet/jee/org.restlet/2.3.0/org.restlet-2.3.0.pom) while downloading https://repo1.maven.org/maven2/org/restlet/jee/org.restlet/2.3.0/org.restlet-2.3.0.pom\n",
      "Obtained 388 files\n",
      "Marking com.google.guava:guava:15.0 for download\n",
      "Obtained 2 files\n",
      "Marking org.jsoup:jsoup:1.11.3 for download\n",
      "Obtained 2 files\n"
     ]
    }
   ],
   "source": [
    "%AddDeps com.lucidworks.spark spark-solr 3.6.0 --transitive\n",
    "%AddDeps com.google.guava guava 15.0 --transitive\n",
    "%AddDeps org.jsoup jsoup 1.11.3 --transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from matplotlib) (1.16.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: setuptools in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: networkx in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (2.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/raclancy/miniconda3/envs/sparksolrini/lib/python3.7/site-packages (from networkx) (4.4.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "warning: there were two feature warnings; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "\n",
    "\"pip install matplotlib\" !\n",
    "\n",
    "\"pip install networkx\" !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Solr\n",
    "\n",
    "First we extract links referenced by websites in the ClueWeb09b collection that contain the word \"jaguar\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOLR = 192.168.1.111:9983\n",
       "INDEX = cw09b-url\n",
       "QUERY = contents:jaguar\n",
       "PARTITIONS = 8\n",
       "LIMIT = 10000\n",
       "OUT_DIR = link_analysis\n",
       "source_urls = MapPartitionsRDD[417] at mapPartitions at <console>:456\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[417] at mapPartitions at <console>:456"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.lucidworks.spark.rdd.SelectSolrRDD\n",
    "import com.google.common.net.InternetDomainName\n",
    "import org.jsoup.Jsoup\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "\n",
    "import scala.collection.JavaConverters._\n",
    "import java.net.URL\n",
    "\n",
    "// Solr's ZooKeeper URL\n",
    "val SOLR = \"192.168.1.111:9983\"\n",
    "\n",
    "// The Solr collection\n",
    "val INDEX = \"cw09b-url\"\n",
    "\n",
    "// The Solr query\n",
    "val QUERY = \"contents:jaguar\"\n",
    "\n",
    "// The number of partitions\n",
    "val PARTITIONS = 8\n",
    "\n",
    "// The limit for number of rows to process\n",
    "val LIMIT = 10000\n",
    "\n",
    "val source_urls = new SelectSolrRDD(SOLR, INDEX, sc, maxRows = Some(LIMIT))\n",
    ".rows(10000)\n",
    ".query(QUERY)\n",
    ".repartition(PARTITIONS)\n",
    ".mapPartitions(docs => {\n",
    "    docs.map(doc => {\n",
    "        val url = doc.get(\"url\") + \"\"\n",
    "        try { (InternetDomainName.from(new URL(url.substring(1, url.length - 1)).getHost).topPrivateDomain().name(), doc.get(\"raw\") + \"\") }\n",
    "        catch {\n",
    "            case e: Exception => println(\"\")\n",
    "            (\"\", \"\")\n",
    "        }\n",
    "    })\n",
    "    .filter(!_._2.isEmpty)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Links\n",
    "\n",
    "We then randomly sample 1% of the retrieved documents and extract the top three most frequently-occurring outgoing links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT_DIR = link_analysis\n",
       "zipped_urls = CoalescedRDD[425] at coalesce at <console>:457\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(wikipedia.org;49ers.com)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// The output path\n",
    "val OUT_DIR = \"link_analysis\"\n",
    "\n",
    "// Delete old output dir\n",
    "FileSystem.get(sc.hadoopConfiguration).delete(new Path(OUT_DIR), true)\n",
    "\n",
    "val zipped_urls = source_urls.sample(withReplacement=false, fraction=0.01, seed=42)\n",
    ".flatMap(record => {\n",
    "        val target_urls = Jsoup.parse(record._2)\n",
    "          .select(\"a[href]\")\n",
    "          .asScala\n",
    "          .map(link => link.attr(\"abs:href\"))\n",
    "          .filter(!_.isEmpty)\n",
    "          .map(link => {\n",
    "            try { InternetDomainName.from(new URL(link).getHost).topPrivateDomain().name() }\n",
    "            catch {\n",
    "              case e: Exception => println(\"\")\n",
    "                \"\"\n",
    "            }\n",
    "          })\n",
    "          .distinct\n",
    "          .take(3)\n",
    "        val src_host = (1 to target_urls.size).map(_ => record._1)\n",
    "        src_host zip target_urls\n",
    "      })\n",
    "      .distinct\n",
    "      .filter(x => x._1 != x._2)\n",
    "      .map(pair => pair._1 + \";\" + pair._2)\n",
    "      .coalesce(1)\n",
    "\n",
    "zipped_urls.saveAsTextFile(OUT_DIR)\n",
    "zipped_urls.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Network Graph\n",
    "\n",
    "The output contains a list of semi-column separated domain pairs.\n",
    "You may directly feed this file into your favorite visualization tool to create a network graph.\n",
    "We use Gephi with Multilevel Layout in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Nhome/raclancy/miniame: \n",
      "Type: Graph\n",
      "Number of nodes: 182\n",
      "Number of edges: 149\n",
      "Average degree:   1.6374\n",
      "conda3/envs/sparksolrini/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "warning: there were three feature warnings; re-run with -feature for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "\n",
    "// Remove the old output directory\n",
    "\"rm -rf network_graph.png /tmp/link_analysis\" !\n",
    "\n",
    "// Copy new output from HDFS to local filesystem\n",
    "\"hdfs dfs -copyToLocal link_analysis /tmp/link_analysis\" !\n",
    "\n",
    "// Draw the graph\n",
    "\"python draw_graph.py\" !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](network_graph.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
