2018-12-04 19:26:11 WARN  Utils:66 - Kubernetes master URL uses HTTP instead of HTTPS.
2018-12-04 19:26:11 WARN  Utils:66 - Your hostname, tem127 resolves to a loopback address: 127.0.1.1; using 192.168.152.227 instead (on interface eno1)
2018-12-04 19:26:11 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2018-12-04 19:26:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
log4j:ERROR Could not read configuration file [log4j.properties].
java.io.FileNotFoundException: log4j.properties (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at java.io.FileInputStream.<init>(FileInputStream.java:93)
	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:372)
	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:403)
	at ca.uwaterloo.cs848.SolrSpark$.<init>(SolrSpark.scala:13)
	at ca.uwaterloo.cs848.SolrSpark$.<clinit>(SolrSpark.scala)
	at ca.uwaterloo.cs848.SolrSpark.main(SolrSpark.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:849)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:167)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:195)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log4j:ERROR Ignoring configuration file [log4j.properties].
2018-12-04 19:26:12 INFO  SolrSpark$:19 - Scallop(--term, kind, --field, raw, --solr, 192.168.152.201:32181, --index, gov2)
 *  field => raw
 *  term => kind
 *  solr => 192.168.152.201:32181
 *  index => gov2
    rows => 1000
    debug => false

2018-12-04 19:26:12 INFO  SparkContext:54 - Running Spark version 2.4.0
2018-12-04 19:26:12 INFO  SparkContext:54 - Submitted application: SolrSpark$
2018-12-04 19:26:12 INFO  SecurityManager:54 - Changing view acls to: root
2018-12-04 19:26:12 INFO  SecurityManager:54 - Changing modify acls to: root
2018-12-04 19:26:12 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-04 19:26:12 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-04 19:26:12 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-12-04 19:26:12 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 36173.
2018-12-04 19:26:12 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-04 19:26:13 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-04 19:26:13 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-04 19:26:13 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-04 19:26:13 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-8ec8e89c-76e8-4862-a3cd-c2ed1206e73e
2018-12-04 19:26:13 INFO  MemoryStore:54 - MemoryStore started with capacity 8.4 GB
2018-12-04 19:26:13 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-04 19:26:13 INFO  log:192 - Logging initialized @3008ms
2018-12-04 19:26:13 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2018-12-04 19:26:13 INFO  Server:419 - Started @3111ms
2018-12-04 19:26:13 INFO  AbstractConnector:278 - Started ServerConnector@4604b900{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-04 19:26:13 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@907f2b7{/jobs,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64040287{/jobs/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@110844f6{/jobs/job,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@df1cff6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4925f4f5{/stages,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ad926d3{/stages/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a43d133{/stages/stage,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c96a4ea{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28782602{/stages/pool,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60c16548{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68105edc{/storage,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@511816c0{/storage/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38b972d7{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5339bbad{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3935e9a8{/environment,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@288a4658{/environment/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5b56b654{/executors,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@452c8a40{/executors/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@534243e4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29006752{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@470a9030{/static,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f8890c2{/,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@607b2792{/api,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31611954{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e598df9{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-04 19:26:13 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://192.168.152.227:4040
2018-12-04 19:26:13 INFO  SparkContext:54 - Added JAR file:/hdd1/CS848-project/target/cs848-project-1.0-SNAPSHOT.jar at spark://192.168.152.227:36173/jars/cs848-project-1.0-SNAPSHOT.jar with timestamp 1543969573370
2018-12-04 19:26:13 WARN  Config:347 - Error reading service account token from: [/var/run/secrets/kubernetes.io/serviceaccount/token]. Ignoring.
2018-12-04 19:26:13 INFO  ExecutorPodsAllocator:54 - Going to request 5 executors from Kubernetes.
2018-12-04 19:26:14 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45743.
2018-12-04 19:26:14 INFO  NettyBlockTransferService:54 - Server created on 192.168.152.227:45743
2018-12-04 19:26:14 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-04 19:26:14 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 192.168.152.227, 45743, None)
2018-12-04 19:26:14 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.152.227:45743 with 8.4 GB RAM, BlockManagerId(driver, 192.168.152.227, 45743, None)
2018-12-04 19:26:14 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 192.168.152.227, 45743, None)
2018-12-04 19:26:14 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 192.168.152.227, 45743, None)
2018-12-04 19:26:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1706a5c9{/metrics/json,null,AVAILABLE,@Spark}
2018-12-04 19:26:25 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.152.204:49190) with ID 1
2018-12-04 19:26:26 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.233.74.75:38705 with 4.4 GB RAM, BlockManagerId(1, 10.233.74.75, 38705, None)
2018-12-04 19:26:26 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.152.205:53376) with ID 2
2018-12-04 19:26:26 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.233.97.156:37065 with 4.4 GB RAM, BlockManagerId(2, 10.233.97.156, 37065, None)
2018-12-04 19:26:28 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.152.201:50976) with ID 4
2018-12-04 19:26:28 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.152.203:48142) with ID 3
2018-12-04 19:26:29 INFO  KubernetesClusterSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2018-12-04 19:26:29 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.233.102.172:40469 with 4.4 GB RAM, BlockManagerId(4, 10.233.102.172, 40469, None)
2018-12-04 19:26:29 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.233.71.62:38927 with 4.4 GB RAM, BlockManagerId(3, 10.233.71.62, 38927, None)
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:host.name=tem127.tembo-domain.cs.uwaterloo.ca
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:java.version=1.8.0_181
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:java.vendor=Oracle Corporation
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:java.class.path=/home/username/spark-2.4.0-bin-hadoop2.7/conf/:/home/username/spark-2.4.0-bin-hadoop2.7/jars/calcite-avatica-1.2.0-incubating.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/snappy-0.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/machinist_2.11-0.6.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/opencsv-2.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/datanucleus-core-3.2.10.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-mllib-local_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/paranamer-2.8.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-module-scala_2.11-2.6.7.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-1.7.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/orc-core-1.5.2-nohive.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-lang3-3.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jersey-server-2.22.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-compiler-3.0.9.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-annotations-2.6.7.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/kubernetes-client-3.0.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/log4j-1.2.17.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/ST4-4.0.4.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/janino-3.0.9.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/JavaEWAH-0.3.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/scala-parser-combinators_2.11-1.1.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/xmlenc-0.52.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-io-2.4.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/lz4-java-1.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/antlr-runtime-3.4.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/validation-api-1.1.0.Final.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/zstd-jni-1.3.2-2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/datanucleus-rdbms-3.2.9.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/scala-reflect-2.11.12.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/libthrift-0.9.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jetty-6.1.26.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/datanucleus-api-jdo-3.2.6.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/stringtemplate-3.2.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-repl_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jersey-guava-2.22.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/core-1.1.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/breeze_2.11-0.13.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/logging-interceptor-3.8.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hive-exec-1.2.1.spark2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/json4s-core_2.11-3.5.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0-tests.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-1.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/javax.ws.rs-api-2.0.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-graphx_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hppc-0.7.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/metrics-jvm-3.1.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-sketch_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/httpcore-4.4.10.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/py4j-0.10.7.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-net-3.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/aircompressor-0.10.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-launcher_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/automaton-1.11-8.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/curator-client-2.7.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/snakeyaml-1.15.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hk2-utils-2.4.0-b34.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.6.7.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/metrics-json-3.1.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/guava-14.0.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-2.22.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/metrics-core-3.1.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.22.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-yarn_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-mesos_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jline-2.14.6.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spire-macros_2.11-0.13.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jersey-client-2.22.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/ivy-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/pyrolite-4.13.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/xz-1.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/zookeeper-3.4.6.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/javassist-3.18.1-GA.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hk2-locator-2.4.0-b34.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-hive_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/calcite-linq4j-1.2.0-incubating.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/avro-1.8.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0-2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/chill_2.11-0.9.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-core-1.8.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/javolution-5.5.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/okhttp-3.8.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/parquet-jackson-1.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-kvstore_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/guice-3.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jpam-1.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-client-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hk2-api-2.4.0-b34.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/json4s-jackson_2.11-3.5.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/breeze-macros_2.11-0.13.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/eigenbase-properties-1.1.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/RoaringBitmap-0.5.11.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/shapeless_2.11-2.3.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/activation-1.1.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-cli-1.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jersey-common-2.22.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/httpclient-4.5.6.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/snappy-java-1.1.7.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-sql_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/arrow-vector-0.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jsp-api-2.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jta-1.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-module-paranamer-2.7.9.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-databind-2.6.7.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hive-beeline-1.2.1.spark2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-streaming_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.6.7.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-core_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/scala-library-2.11.12.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/parquet-column-1.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/objenesis-2.5.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/chill-java-0.9.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/arrow-format-0.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/apache-log4j-extras-1.2.17.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/json4s-ast_2.11-3.5.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/antlr4-runtime-4.7.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/json4s-scalap_2.11-3.5.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/gson-2.2.4.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/arrow-memory-0.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-kubernetes_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/macro-compat_2.11-1.1.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/scala-compiler-2.11.12.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/orc-mapreduce-1.5.2-nohive.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jsr305-1.3.9.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.4.0-b34.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-digester-1.8.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/stream-2.7.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/javax.inject-1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/xbean-asm6-shaded-4.8.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/orc-shims-1.5.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/antlr-2.7.7.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/parquet-encoding-1.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-mllib_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jtransforms-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hive-metastore-1.2.1.spark2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/parquet-common-1.10.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/kubernetes-model-2.0.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/metrics-graphite-3.1.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/parquet-format-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/minlog-1.3.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/flatbuffers-1.2.0-3f79e055.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/generex-1.0.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-compress-1.8.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/netty-3.9.9.Final.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/okio-1.13.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/joda-time-2.9.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/javax.inject-2.4.0-b34.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/aopalliance-1.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/curator-framework-2.7.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-network-shuffle_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/netty-all-4.1.17.Final.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/calcite-core-1.2.0-incubating.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spire_2.11-0.13.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jackson-core-2.6.7.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/javax.annotation-api-1.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/oro-2.0.8.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/univocity-parsers-2.7.3.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-lang-2.6.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-bundle-1.6.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/hive-cli-1.2.1.spark2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/scala-xml_2.11-1.0.5.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/spark-network-common_2.11-2.4.0.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/jersey-media-jaxb-2.22.2.jar:/home/username/spark-2.4.0-bin-hadoop2.7/jars/commons-codec-1.10.jar:/home/username/hdfs_conf/
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:java.io.tmpdir=/tmp
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:java.compiler=<NA>
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:os.name=Linux
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:os.arch=amd64
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:os.version=4.15.0-33-generic
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:user.name=root
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:user.home=/root
2018-12-04 19:26:29 INFO  ZooKeeper:100 - Client environment:user.dir=/home/username/spark-2.4.0-bin-hadoop2.7
2018-12-04 19:26:29 INFO  ZooKeeper:438 - Initiating client connection, connectString=192.168.152.201:32181 sessionTimeout=30000 watcher=org.apache.solr.common.cloud.SolrZkClient$1@76db540e
2018-12-04 19:26:29 INFO  ClientCnxn:975 - Opening socket connection to server 192.168.152.201/192.168.152.201:32181. Will not attempt to authenticate using SASL (unknown error)
2018-12-04 19:26:29 INFO  ClientCnxn:852 - Socket connection established to 192.168.152.201/192.168.152.201:32181, initiating session
2018-12-04 19:26:29 INFO  ClientCnxn:1235 - Session establishment complete on server 192.168.152.201/192.168.152.201:32181, sessionid = 0x36762080b9a001a, negotiated timeout = 30000
2018-12-04 19:26:29 INFO  ConnectionManager:119 - zkClient has connected
2018-12-04 19:26:29 INFO  ZkStateReader:786 - Updated live nodes from ZooKeeper... (0) -> (5)
2018-12-04 19:26:29 INFO  ZkClientClusterStateProvider:158 - Cluster at 192.168.152.201:32181 ready
2018-12-04 19:26:29 INFO  SelectSolrRDD:8 - Updated Solr query: q=raw:kind&rows=1000&collection=gov2&distrib=false&start=0&sort=id+asc&fq=_version_:[*+TO+1618535134362861568]
2018-12-04 19:26:29 INFO  SelectSolrRDD:8 - Found 50 partitions
2018-12-04 19:26:29 INFO  SparkContext:54 - Starting job: foreach at SolrSpark.scala:33
2018-12-04 19:26:29 INFO  DAGScheduler:54 - Got job 0 (foreach at SolrSpark.scala:33) with 50 output partitions
2018-12-04 19:26:29 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (foreach at SolrSpark.scala:33)
2018-12-04 19:26:29 INFO  DAGScheduler:54 - Parents of final stage: List()
2018-12-04 19:26:29 INFO  DAGScheduler:54 - Missing parents: List()
2018-12-04 19:26:29 INFO  DAGScheduler:54 - Submitting ResultStage 0 (SelectSolrRDD[2] at RDD at SolrRDD.scala:26), which has no missing parents
2018-12-04 19:26:29 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 2.2 KB, free 8.4 GB)
2018-12-04 19:26:29 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1608.0 B, free 8.4 GB)
2018-12-04 19:26:29 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.152.227:45743 (size: 1608.0 B, free: 8.4 GB)
2018-12-04 19:26:29 INFO  SparkContext:54 - Created broadcast 0 from broadcast at DAGScheduler.scala:1161
2018-12-04 19:26:29 INFO  DAGScheduler:54 - Submitting 50 missing tasks from ResultStage 0 (SelectSolrRDD[2] at RDD at SolrRDD.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-12-04 19:26:29 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 50 tasks
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, 10.233.97.156, executor 2, partition 0, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, 10.233.74.75, executor 1, partition 1, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, 10.233.71.62, executor 3, partition 2, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, 10.233.102.172, executor 4, partition 3, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 4.0 in stage 0.0 (TID 4, 10.233.97.156, executor 2, partition 4, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 5.0 in stage 0.0 (TID 5, 10.233.74.75, executor 1, partition 5, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 6.0 in stage 0.0 (TID 6, 10.233.71.62, executor 3, partition 6, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 7, 10.233.102.172, executor 4, partition 7, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 8.0 in stage 0.0 (TID 8, 10.233.97.156, executor 2, partition 8, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 9, 10.233.74.75, executor 1, partition 9, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 10.0 in stage 0.0 (TID 10, 10.233.71.62, executor 3, partition 10, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 11.0 in stage 0.0 (TID 11, 10.233.102.172, executor 4, partition 11, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 12.0 in stage 0.0 (TID 12, 10.233.97.156, executor 2, partition 12, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 13.0 in stage 0.0 (TID 13, 10.233.74.75, executor 1, partition 13, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 14.0 in stage 0.0 (TID 14, 10.233.71.62, executor 3, partition 14, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 15.0 in stage 0.0 (TID 15, 10.233.102.172, executor 4, partition 15, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 16.0 in stage 0.0 (TID 16, 10.233.97.156, executor 2, partition 16, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 17.0 in stage 0.0 (TID 17, 10.233.74.75, executor 1, partition 17, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 18.0 in stage 0.0 (TID 18, 10.233.71.62, executor 3, partition 18, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 19.0 in stage 0.0 (TID 19, 10.233.102.172, executor 4, partition 19, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 20.0 in stage 0.0 (TID 20, 10.233.97.156, executor 2, partition 20, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 21.0 in stage 0.0 (TID 21, 10.233.74.75, executor 1, partition 21, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 22.0 in stage 0.0 (TID 22, 10.233.71.62, executor 3, partition 22, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 23.0 in stage 0.0 (TID 23, 10.233.102.172, executor 4, partition 23, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 24.0 in stage 0.0 (TID 24, 10.233.97.156, executor 2, partition 24, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 25.0 in stage 0.0 (TID 25, 10.233.74.75, executor 1, partition 25, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 26.0 in stage 0.0 (TID 26, 10.233.71.62, executor 3, partition 26, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 27.0 in stage 0.0 (TID 27, 10.233.102.172, executor 4, partition 27, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 28.0 in stage 0.0 (TID 28, 10.233.97.156, executor 2, partition 28, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 29.0 in stage 0.0 (TID 29, 10.233.74.75, executor 1, partition 29, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 30.0 in stage 0.0 (TID 30, 10.233.71.62, executor 3, partition 30, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 31.0 in stage 0.0 (TID 31, 10.233.102.172, executor 4, partition 31, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 32.0 in stage 0.0 (TID 32, 10.233.97.156, executor 2, partition 32, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 33.0 in stage 0.0 (TID 33, 10.233.74.75, executor 1, partition 33, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 34.0 in stage 0.0 (TID 34, 10.233.71.62, executor 3, partition 34, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 35.0 in stage 0.0 (TID 35, 10.233.102.172, executor 4, partition 35, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 36.0 in stage 0.0 (TID 36, 10.233.97.156, executor 2, partition 36, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 37.0 in stage 0.0 (TID 37, 10.233.74.75, executor 1, partition 37, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 38.0 in stage 0.0 (TID 38, 10.233.71.62, executor 3, partition 38, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 39.0 in stage 0.0 (TID 39, 10.233.102.172, executor 4, partition 39, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 40.0 in stage 0.0 (TID 40, 10.233.97.156, executor 2, partition 40, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 41.0 in stage 0.0 (TID 41, 10.233.74.75, executor 1, partition 41, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 42.0 in stage 0.0 (TID 42, 10.233.71.62, executor 3, partition 42, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 43.0 in stage 0.0 (TID 43, 10.233.102.172, executor 4, partition 43, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.152.202:48724) with ID 5
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 44.0 in stage 0.0 (TID 44, 10.233.75.10, executor 5, partition 44, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 45.0 in stage 0.0 (TID 45, 10.233.75.10, executor 5, partition 45, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 46.0 in stage 0.0 (TID 46, 10.233.75.10, executor 5, partition 46, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 47.0 in stage 0.0 (TID 47, 10.233.75.10, executor 5, partition 47, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 48.0 in stage 0.0 (TID 48, 10.233.75.10, executor 5, partition 48, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  TaskSetManager:54 - Starting task 49.0 in stage 0.0 (TID 49, 10.233.75.10, executor 5, partition 49, ANY, 9173 bytes)
2018-12-04 19:26:30 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.233.75.10:41403 with 4.4 GB RAM, BlockManagerId(5, 10.233.75.10, 41403, None)
2018-12-04 19:26:38 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.233.74.75:38705 (size: 1608.0 B, free: 4.4 GB)
2018-12-04 19:26:39 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.233.75.10:41403 (size: 1608.0 B, free: 4.4 GB)
2018-12-04 19:26:39 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.233.71.62:38927 (size: 1608.0 B, free: 4.4 GB)
2018-12-04 19:26:41 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.233.102.172:40469 (size: 1608.0 B, free: 4.4 GB)
2018-12-04 19:26:41 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.233.97.156:37065 (size: 1608.0 B, free: 4.4 GB)
2018-12-04 19:27:32 INFO  TaskSetManager:54 - Finished task 20.0 in stage 0.0 (TID 20) in 62234 ms on 10.233.97.156 (executor 2) (1/50)
2018-12-04 19:27:32 INFO  TaskSetManager:54 - Finished task 28.0 in stage 0.0 (TID 28) in 62431 ms on 10.233.97.156 (executor 2) (2/50)
2018-12-04 19:27:33 INFO  TaskSetManager:54 - Finished task 24.0 in stage 0.0 (TID 24) in 63470 ms on 10.233.97.156 (executor 2) (3/50)
2018-12-04 19:27:34 INFO  TaskSetManager:54 - Finished task 21.0 in stage 0.0 (TID 21) in 64503 ms on 10.233.74.75 (executor 1) (4/50)
2018-12-04 19:27:37 INFO  TaskSetManager:54 - Finished task 37.0 in stage 0.0 (TID 37) in 66925 ms on 10.233.74.75 (executor 1) (5/50)
2018-12-04 19:27:38 INFO  TaskSetManager:54 - Finished task 25.0 in stage 0.0 (TID 25) in 68273 ms on 10.233.74.75 (executor 1) (6/50)
2018-12-04 19:27:40 INFO  TaskSetManager:54 - Finished task 29.0 in stage 0.0 (TID 29) in 70037 ms on 10.233.74.75 (executor 1) (7/50)
2018-12-04 19:27:40 INFO  TaskSetManager:54 - Finished task 26.0 in stage 0.0 (TID 26) in 70641 ms on 10.233.71.62 (executor 3) (8/50)
2018-12-04 19:27:41 INFO  TaskSetManager:54 - Finished task 32.0 in stage 0.0 (TID 32) in 71635 ms on 10.233.97.156 (executor 2) (9/50)
2018-12-04 19:27:42 INFO  TaskSetManager:54 - Finished task 22.0 in stage 0.0 (TID 22) in 72602 ms on 10.233.71.62 (executor 3) (10/50)
2018-12-04 19:27:48 INFO  TaskSetManager:54 - Finished task 23.0 in stage 0.0 (TID 23) in 78591 ms on 10.233.102.172 (executor 4) (11/50)
2018-12-04 19:27:48 INFO  TaskSetManager:54 - Finished task 35.0 in stage 0.0 (TID 35) in 78678 ms on 10.233.102.172 (executor 4) (12/50)
2018-12-04 19:27:51 INFO  TaskSetManager:54 - Finished task 27.0 in stage 0.0 (TID 27) in 81216 ms on 10.233.102.172 (executor 4) (13/50)
2018-12-04 19:28:02 INFO  TaskSetManager:54 - Finished task 33.0 in stage 0.0 (TID 33) in 92770 ms on 10.233.74.75 (executor 1) (14/50)
2018-12-04 19:28:10 INFO  TaskSetManager:54 - Finished task 34.0 in stage 0.0 (TID 34) in 100506 ms on 10.233.71.62 (executor 3) (15/50)
2018-12-04 19:28:12 INFO  TaskSetManager:54 - Finished task 38.0 in stage 0.0 (TID 38) in 102053 ms on 10.233.71.62 (executor 3) (16/50)
2018-12-04 19:28:13 INFO  TaskSetManager:54 - Finished task 30.0 in stage 0.0 (TID 30) in 102984 ms on 10.233.71.62 (executor 3) (17/50)
2018-12-04 19:28:19 INFO  TaskSetManager:54 - Finished task 36.0 in stage 0.0 (TID 36) in 109493 ms on 10.233.97.156 (executor 2) (18/50)
2018-12-04 19:28:20 INFO  TaskSetManager:54 - Finished task 31.0 in stage 0.0 (TID 31) in 110120 ms on 10.233.102.172 (executor 4) (19/50)
2018-12-04 19:28:22 INFO  TaskSetManager:54 - Finished task 39.0 in stage 0.0 (TID 39) in 112155 ms on 10.233.102.172 (executor 4) (20/50)
2018-12-04 19:29:35 INFO  TaskSetManager:54 - Finished task 42.0 in stage 0.0 (TID 42) in 185216 ms on 10.233.71.62 (executor 3) (21/50)
2018-12-04 19:29:36 INFO  TaskSetManager:54 - Finished task 47.0 in stage 0.0 (TID 47) in 185696 ms on 10.233.75.10 (executor 5) (22/50)
2018-12-04 19:29:59 INFO  TaskSetManager:54 - Finished task 43.0 in stage 0.0 (TID 43) in 209571 ms on 10.233.102.172 (executor 4) (23/50)
2018-12-04 19:30:01 INFO  TaskSetManager:54 - Finished task 44.0 in stage 0.0 (TID 44) in 210549 ms on 10.233.75.10 (executor 5) (24/50)
2018-12-04 19:30:03 INFO  TaskSetManager:54 - Finished task 40.0 in stage 0.0 (TID 40) in 213732 ms on 10.233.97.156 (executor 2) (25/50)
2018-12-04 19:30:03 INFO  TaskSetManager:54 - Finished task 46.0 in stage 0.0 (TID 46) in 213272 ms on 10.233.75.10 (executor 5) (26/50)
2018-12-04 19:30:04 INFO  TaskSetManager:54 - Finished task 48.0 in stage 0.0 (TID 48) in 213674 ms on 10.233.75.10 (executor 5) (27/50)
2018-12-04 19:30:04 INFO  TaskSetManager:54 - Finished task 41.0 in stage 0.0 (TID 41) in 214727 ms on 10.233.74.75 (executor 1) (28/50)
2018-12-04 19:30:06 INFO  TaskSetManager:54 - Finished task 49.0 in stage 0.0 (TID 49) in 215688 ms on 10.233.75.10 (executor 5) (29/50)
2018-12-04 19:30:07 INFO  TaskSetManager:54 - Finished task 45.0 in stage 0.0 (TID 45) in 216772 ms on 10.233.75.10 (executor 5) (30/50)
2018-12-04 19:30:21 INFO  TaskSetManager:54 - Finished task 10.0 in stage 0.0 (TID 10) in 231875 ms on 10.233.71.62 (executor 3) (31/50)
2018-12-04 19:30:22 INFO  TaskSetManager:54 - Finished task 11.0 in stage 0.0 (TID 11) in 232795 ms on 10.233.102.172 (executor 4) (32/50)
2018-12-04 19:30:23 INFO  TaskSetManager:54 - Finished task 18.0 in stage 0.0 (TID 18) in 233252 ms on 10.233.71.62 (executor 3) (33/50)
2018-12-04 19:30:24 INFO  TaskSetManager:54 - Finished task 12.0 in stage 0.0 (TID 12) in 234250 ms on 10.233.97.156 (executor 2) (34/50)
2018-12-04 19:30:24 INFO  TaskSetManager:54 - Finished task 16.0 in stage 0.0 (TID 16) in 234827 ms on 10.233.97.156 (executor 2) (35/50)
2018-12-04 19:30:24 INFO  TaskSetManager:54 - Finished task 14.0 in stage 0.0 (TID 14) in 234835 ms on 10.233.71.62 (executor 3) (36/50)
2018-12-04 19:30:25 INFO  TaskSetManager:54 - Finished task 19.0 in stage 0.0 (TID 19) in 235033 ms on 10.233.102.172 (executor 4) (37/50)
2018-12-04 19:30:25 INFO  TaskSetManager:54 - Finished task 15.0 in stage 0.0 (TID 15) in 235044 ms on 10.233.102.172 (executor 4) (38/50)
2018-12-04 19:30:25 INFO  TaskSetManager:54 - Finished task 17.0 in stage 0.0 (TID 17) in 235043 ms on 10.233.74.75 (executor 1) (39/50)
2018-12-04 19:30:25 INFO  TaskSetManager:54 - Finished task 13.0 in stage 0.0 (TID 13) in 235191 ms on 10.233.74.75 (executor 1) (40/50)
2018-12-04 19:30:48 INFO  TaskSetManager:54 - Finished task 6.0 in stage 0.0 (TID 6) in 258063 ms on 10.233.71.62 (executor 3) (41/50)
2018-12-04 19:30:48 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 258409 ms on 10.233.71.62 (executor 3) (42/50)
2018-12-04 19:30:48 INFO  TaskSetManager:54 - Finished task 4.0 in stage 0.0 (TID 4) in 258557 ms on 10.233.97.156 (executor 2) (43/50)
2018-12-04 19:30:49 INFO  TaskSetManager:54 - Finished task 8.0 in stage 0.0 (TID 8) in 259410 ms on 10.233.97.156 (executor 2) (44/50)
2018-12-04 19:30:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 259455 ms on 10.233.97.156 (executor 2) (45/50)
2018-12-04 19:30:49 INFO  TaskSetManager:54 - Finished task 5.0 in stage 0.0 (TID 5) in 259587 ms on 10.233.74.75 (executor 1) (46/50)
2018-12-04 19:30:49 INFO  TaskSetManager:54 - Finished task 7.0 in stage 0.0 (TID 7) in 259832 ms on 10.233.102.172 (executor 4) (47/50)
2018-12-04 19:30:49 INFO  TaskSetManager:54 - Finished task 3.0 in stage 0.0 (TID 3) in 259839 ms on 10.233.102.172 (executor 4) (48/50)
2018-12-04 19:30:50 INFO  TaskSetManager:54 - Finished task 9.0 in stage 0.0 (TID 9) in 259978 ms on 10.233.74.75 (executor 1) (49/50)
2018-12-04 19:30:50 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 260593 ms on 10.233.74.75 (executor 1) (50/50)
2018-12-04 19:30:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-04 19:30:50 INFO  DAGScheduler:54 - ResultStage 0 (foreach at SolrSpark.scala:33) finished in 260.856 s
2018-12-04 19:30:50 INFO  DAGScheduler:54 - Job 0 finished: foreach at SolrSpark.scala:33, took 260.938538 s
2018-12-04 19:30:50 INFO  SolrSpark$:42 - Took 261689ms
2018-12-04 19:30:50 INFO  AbstractConnector:318 - Stopped Spark@4604b900{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-04 19:30:50 INFO  SparkUI:54 - Stopped Spark web UI at http://192.168.152.227:4040
2018-12-04 19:30:50 INFO  KubernetesClusterSchedulerBackend:54 - Shutting down all executors
2018-12-04 19:30:50 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Asking each executor to shut down
2018-12-04 19:30:50 INFO  ZooKeeper:684 - Session: 0x36762080b9a001a closed
2018-12-04 19:30:50 INFO  ClientCnxn:512 - EventThread shut down
2018-12-04 19:30:50 WARN  ExecutorPodsWatchSnapshotSource:87 - Kubernetes client has been closed (this is expected if the application is shutting down.)
2018-12-04 19:30:51 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-04 19:30:51 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-04 19:30:51 INFO  BlockManager:54 - BlockManager stopped
2018-12-04 19:30:51 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-04 19:30:51 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-04 19:30:51 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-04 19:30:51 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-04 19:30:51 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-170d2126-27d5-4164-b743-b0fe50347c72
2018-12-04 19:30:51 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-3367f128-42da-4793-9bdf-1aaf8181b02e
